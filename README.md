ğŸ“„ Gemini-Powered Document Question Answering System
<p align="center"> <img src="https://img.shields.io/badge/Version-1.0-blue?style=for-the-badge" /> <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python" /> <img src="https://img.shields.io/badge/Streamlit-App-FF4B4B?style=for-the-badge&logo=streamlit" /> <img src="https://img.shields.io/badge/Gemini-API-4285F4?style=for-the-badge&logo=google" /> <img src="https://img.shields.io/badge/Database-SQLite-003B57?style=for-the-badge&logo=sqlite" /> <img src="https://img.shields.io/badge/LLM-Gemini_Pro-brightgreen?style=for-the-badge" /> <img src="https://img.shields.io/badge/Status-Active-brightgreen?style=for-the-badge" /> </p>
ğŸ“Œ Overview

The Gemini Document Question Answering System is an AI assistant that reads documents, extracts knowledge, and answers complex questions using Google Gemini models.

This system supports:

ğŸ“„ Multi-document upload (PDF/TXT)

ğŸ§© Semantic chunking

ğŸ”¢ Embedding-based RAG retrieval

ğŸ¤– Gemini-Pro reasoning

ğŸ” Citation-backed answers

ğŸ¤ Voice input

ğŸ”Š Voice output

ğŸ—‚ Query logging + analytics

ğŸ–¥ Streamlit-based modern UI

Perfect for:

âœ” Legal workflows
âœ” Academic research
âœ” Enterprise documentation
âœ” Compliance analysis
âœ” Knowledge extraction

âœ¨ Key Features
ğŸ§  Gemini-Powered Reasoning

High accuracy using Gemini-Pro and Gemini-Pro-Vision models.

ğŸ“‚ Multi-Document Upload

Supports multiple PDFs/TXT files at once.

ğŸ” RAG + Embeddings

Retrieves only the most relevant segments using embeddings + cosine similarity.

ğŸ¤ Voice Input & ğŸ”Š Output

Hands-free AI interaction.

ğŸ›¡ SQLite Database

Stores embeddings, logs, and metadata.

ğŸ” Gemini API Setup
1ï¸âƒ£ Get Your API Key

ğŸ‘‰ https://aistudio.google.com/app/apikey

2ï¸âƒ£ Create .env File
GENAI_API_KEY=your_api_key_here

3ï¸âƒ£ Load API Key in Code
import os
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
genai.configure(api_key=os.getenv("GENAI_API_KEY"))

ğŸ§© System Architecture (Fixed Mermaid Diagram)
flowchart TB

A([Upload PDF/TXT]) --> B[Document Loader]
B --> C[Text Cleaning & Normalization]
C --> D[Chunking into Semantic Units]

D --> E[Generate Embeddings]
E --> F[Store Embeddings + Metadata in SQLite]

F --> G[Semantic Retriever - Cosine Similarity]
G --> H[Gemini LLM - RAG Pipeline]
H --> I[Generate Answer with Citations]

I --> J[Voice Output - Text to Speech]
A --> K[Voice Input - Speech to Text]

classDef process fill:#61A5FF,stroke:#1A4C8F,color:white;
classDef db fill:#7ED957,stroke:#2E8B2D,color:black;
classDef voice fill:#FFB347,stroke:#A65B00,color:white;

class B,C,D,E process;
class F,G,H process;
class J,K voice;

ğŸ” RAG Pipeline (Fixed Mermaid Diagram)
flowchart TD

A[User Query] --> B[Embed Query]
B --> C[Search Similar Chunks in SQLite]
C --> D[Retrieve Context]

D --> E[Build Prompt with Context + Query]
E --> F[Gemini LLM - generate_content\(\)]
F --> G[Final Answer + Citations]

classDef step fill:#61A5FF,stroke:#1A4C8F,color:white;
classDef llm fill:#4285F4,stroke:#0F3BA3,color:white;

class A,B,C,D,E step;
class F,G llm;

ğŸ—‚ Project Structure
Gemini-Document-QA/
â”‚â”€â”€ app.py                        # Main Streamlit app
â”‚â”€â”€ rag_engine.py                 # RAG pipeline logic
â”‚â”€â”€ embedding_utils.py            # Chunking + embeddings
â”‚â”€â”€ voice_functions.py            # Speech-to-text + TTS
â”‚â”€â”€ database.py                   # SQLite helper
â”‚â”€â”€ app.db                        # Local database
â”‚â”€â”€ requirements.txt              # Dependencies
â”‚â”€â”€ .env                          # Environment variables
â”‚
â”œâ”€â”€ uploaded_docs/                # User-uploaded files
â”œâ”€â”€ pages/                        # Additional UI screens
â””â”€â”€ models/                       # Optional embedding models

âš™ï¸ Installation
1ï¸âƒ£ Clone Repo
git clone https://github.com/your-username/Gemini-Document-QA.git
cd Gemini-Document-QA

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate
# Windows:
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Gemini API Key

Create .env file:

GENAI_API_KEY=your_key_here

5ï¸âƒ£ Run App
streamlit run app.py


Open in browser:
ğŸ‘‰ http://localhost:8501

ğŸ§ª Example Usage
Step 1 â€” Upload Document

Upload Contract.pdf

Step 2 â€” Ask a Question

â€œWhat are the termination clauses?â€

Step 3 â€” Result

âœ” Extracts relevant document chunks
âœ” Processes them through Gemini-Pro
âœ” Provides citations
âœ” Optional audio output

ğŸ›  Tech Stack
Layer	Technology
UI	Streamlit
LLM	Gemini-Pro / Gemini-Pro-Vision
Embeddings	Gemini Embeddings
Vector Search	SQLite + Cosine Similarity
Backend	Python
Voice	SpeechRecognition + TTS
Parsing	PyPDF2, LangChain loaders
ğŸ—º Roadmap

 Highlight referenced text inside PDF

 Multi-user authentication

 Admin dashboard

 Chat history export

 GCP/Railway/Render deployment

 Hybrid mode â†’ Gemini + Local LLM

ğŸ›¡ License

MIT License.

ğŸ‘¤ Author â€” Hasnain Chavhan

AI & Data Science Engineer
Machine Learning â€¢ GenAI â€¢ MLOps

ğŸŒŸ Support

If you found this project helpful, please â­ the repo!
Your support motivates future updates. ğŸš€
